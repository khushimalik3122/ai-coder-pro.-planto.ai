import type { AIMessage } from '../types';

export class GrokAgent {
  private apiKey: string;
  private model: string = 'llama2-70b-4096'; // Use a Groq-supported model

  constructor(apiKey: string, model?: string) {
    this.apiKey = apiKey;
    if (model) {
      this.model = model;
    }
  }

  /**
   * Generate a completion from Groq API using full message history for context-aware chat.
   * @param messages Array of messages (role: 'user' | 'assistant' | 'system', content: string)
   * @param options temperature, maxTokens
   */
  async generateCompletionWithContext(messages: AIMessage[], options?: { temperature?: number; maxTokens?: number }): Promise<string> {
    try {
      const body: any = {
        model: this.model,
        messages: messages,
        max_tokens: options?.maxTokens || 8192,
        temperature: options?.temperature || 0.7
      };

      console.log('Debug: Making request to Groq API (context-aware)');
      const response = await fetch(
        'https://api.groq.com/openai/v1/chat/completions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'User-Agent': 'AI-Coder-Pro/1.0'
          },
          body: JSON.stringify(body)
        }
      );

      console.log('Debug: Groq Response status:', response.status);

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Debug: Groq API Error:', errorText);
        throw new Error(`Grok API Error ${response.status}: ${errorText}`);
      }

      const data = await response.json();
      console.log('Debug: Groq API Response received');

      if (data && data.choices && data.choices.length > 0) {
        return data.choices[0].message.content;
      }
      throw new Error('No completion generated by Groq');
    } catch (err: any) {
      console.error('Debug: Groq Fetch error:', err);
      if (err?.message?.includes('fetch failed') || err?.message?.includes('ENOTFOUND')) {
        throw new Error('Network error: Unable to connect to Groq API. Please check your internet connection and try again.');
      }
      if (err?.message?.includes('401')) {
        throw new Error('Invalid Groq API key. Please check your credentials.');
      }
      if (err?.message?.includes('429')) {
        throw new Error('Grok rate limit exceeded. Please wait and try again later.');
      }
      throw new Error('Failed to generate code from Groq: ' + (err?.message || err));
    }
  }

  /**
   * Legacy single-prompt method for compatibility (wraps in a single user message)
   */
  async generateCompletion(prompt: string, options?: { temperature?: number; maxTokens?: number }): Promise<string> {
    return this.generateCompletionWithContext([
      { role: 'user', content: prompt }
    ], options);
  }

  /**
   * Agentic workflow: Accepts a sequence of steps and context, returns multi-step reasoning or actions.
   * (This is a placeholder for future agentic workflow logic.)
   */
  async runAgenticWorkflow(messages: AIMessage[], workflowInstructions: string, options?: { temperature?: number; maxTokens?: number }): Promise<string> {
    // Prepend system prompt for agentic workflow
    const agenticMessages: AIMessage[] = [
      { role: 'system', content: workflowInstructions },
      ...messages
    ];
    return this.generateCompletionWithContext(agenticMessages, options);
  }
} 